{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'year',\n",
       " 'weekofyear',\n",
       " 'week_start_date',\n",
       " 'ndvi_ne',\n",
       " 'ndvi_nw',\n",
       " 'ndvi_se',\n",
       " 'ndvi_sw',\n",
       " 'precipitation_amt_mm',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_tdtr_k',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'station_precip_mm']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = pd.read_csv('data/dengue_features_train.csv')\n",
    "y_train = pd.read_csv('data/dengue_labels_train.csv')['total_cases']\n",
    "attr = list(X_train_1)\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[X_train_1['weekofyear'] != 53]\n",
    "X_train_1 = X_train_1[X_train_1['weekofyear'] != 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.ContinuityImputer import ContinuityImputer\n",
    "from utils.DataFrameSelector import DataFrameSelector\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', ContinuityImputer(attributes=attr[4:])),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=attr[4:])),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pipeline.fit_transform(X_train_1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "score_metric='neg_mean_absolute_error'\n",
    "jobs=-1 #-1 to make it execute in parallel\n",
    "k_folds=10\n",
    "n_iter_search = 20\n",
    "verbose_level = 1\n",
    "random_n = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = sp_randint(0, 10000)\n",
    "params = {'kernel':['rbf', 'sigmoid','linear'], 'gamma':['scale'], 'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "SVR_optimizer = RandomizedSearchCV(estimator=SVR(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)\n",
    "SVR_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel':['poly'], 'degree':sp_randint(2,8), 'gamma':['scale'], 'C': C},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_poly_optimizer = RandomizedSearchCV(estimator=SVR(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)\n",
    "SVR_poly_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(SVR_optimizer.cv_results_)[['mean_fit_time','param_C', 'param_kernel', 'mean_test_score', 'mean_train_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
