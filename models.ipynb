{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'year',\n",
       " 'weekofyear',\n",
       " 'week_start_date',\n",
       " 'ndvi_ne',\n",
       " 'ndvi_nw',\n",
       " 'ndvi_se',\n",
       " 'ndvi_sw',\n",
       " 'precipitation_amt_mm',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_tdtr_k',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'station_precip_mm']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = pd.read_csv('data/dengue_features_train.csv')\n",
    "y_train = pd.read_csv('data/dengue_labels_train.csv')['total_cases']\n",
    "attr = list(X_train_1)\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bools_to_indexes(booleans):\n",
    "    r = []\n",
    "    for idx, x in enumerate(booleans):\n",
    "        if x:\n",
    "            r.append(idx)\n",
    "    return r\n",
    "\n",
    "idx = bools_to_indexes(X_train_1['weekofyear'] == 53)\n",
    "y_train.drop(idx, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train_1.drop(idx, inplace=True)\n",
    "X_train_1.reset_index(drop=True, inplace=True)\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "score_metric='neg_mean_absolute_error'\n",
    "jobs=-1 #-1 to make it execute in parallel\n",
    "verbose_level = 0\n",
    "random_n = 42\n",
    "base_args = {'estimator': None, 'param_distributions': None, 'n_iter': None, 'scoring': score_metric, 'n_jobs': jobs, 'cv': None, 'verbose': verbose_level, 'random_state': random_n, 'return_train_score': True, 'iid': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "* The results with the kernel *sigmoid* and *poly* were too bad, so we removed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=5\n",
    "n_iter_search = 10\n",
    "C = sp_randint(0, 10000)\n",
    "params = {'kernel':['linear'], 'gamma':['scale'], 'C': C}\n",
    "SVR_optimizer = RandomizedSearchCV(estimator=SVR(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "* 18.01 - with 2 previous weeks & without PCA & with (max_depth=6, min_samples_leaf=0.1611807565247405, min_samples_split=0.11193019906931466)\n",
    "* 18.29 - With PCA at 0.9\n",
    "* 18.27 - With PCA at 0.95\n",
    "* 18.36 - With PCA at 0.65. PCA appears to be only making the model worse.\n",
    "* 18.38 - Without PCA and with previous weeks. Clearly the previous weeks are useful\n",
    "* 17.87 - Without PCA and with 3 previous weeks\n",
    "* 17.86 - Without PCA and with 4 previous weeks\n",
    "* 18.28 - With PCA 0.95 and 3 previous weeks fixed\n",
    "* 9.16 - Without PCA, with 3 weeks and 1 last infection (max_depth=5, min_samples_leaf=0.03, min_samples_split=0.108)\n",
    "* **9.04** - Without PCA, with 3 weeks and 1 last infection (max_depth=5, min_samples_leaf=0.03, min_samples_split=0.108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 100\n",
    "min_samples = sp_uniform(0.01, 0.35)\n",
    "params = {'criterion':['mae'], 'max_depth': sp_randint(2, 10), 'min_samples_split': min_samples, 'min_samples_leaf': min_samples}\n",
    "Tree_optimizer = RandomizedSearchCV(estimator=DecisionTreeRegressor(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "* 18.34 With 4 previous weeks and without PCA\n",
    "* 17.79 With fixed 3 previous weeks and PCA at 0.95 (n_estimators= ?, max_depth = 2, min_samples_leaf=0.112, min_samples_split=0.224)\n",
    "* 17.74 With fixed 3 previous weeks and without PCA (n_estimators= 13 max_depth = 5, min_samples_leaf=0.09, min_samples_split=0.24)\n",
    "* **9.13** with 3 previous weeks and 1 last infected (n_estimators=9 max_depth = 9, min_samples_leaf=0.014, min_samples_split=0.07)\n",
    "* 9.22 with 3 previous weeks and 3 last infected (n_estimators=9 max_depth = 9, min_samples_leaf=0.014, min_samples_split=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 40\n",
    "params = {'n_estimators': sp_randint(2,50), 'criterion':['mae'], 'max_depth': sp_randint(2, 10)}\n",
    "Forest_optimizer = RandomizedSearchCV(estimator=RandomForestRegressor(n_jobs=-1), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost of Trees\n",
    "* 10.78 - With 3 last weeks a 3 last infected \n",
    "* **8.49** - With 3 last weeks a 3 last infected and only max_depth tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 20\n",
    "params = {'n_estimators': sp_randint(40, 100), 'base_estimator__criterion':['mae'], 'base_estimator__max_depth': sp_randint(2,7)}\n",
    "AdaTree_optimizer = RandomizedSearchCV(estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor()), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "* 21.349 - with PCA at 0.65 & 2 previous weeks\n",
    "* 20.36  - without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 100\n",
    "params = {'n_neighbors': sp_randint(3,150), 'weights': ['uniform', 'distance']}\n",
    "KNN_optimizer = RandomizedSearchCV(estimator=KNeighborsRegressor(n_jobs=-1), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most simple prediction\n",
    "* Our first attempt consists of simply adding weather information from the previous weeks and finding the optimal the optimal parameter through exaustive search (coded by us) and find its optimal hyper-parameters (using `RandomSearchCV`).\n",
    "* Interestingly, PCA makes all the models worst in this case.\n",
    "* It turned out to be a `RandomForestRegressor` as you can see in the `best_attempt` variable. By using this model and adding the 3 previous weeks of weather to each entry, we obtained a MAE of approximately 17 by 10-folded cross validation.\n",
    "* Unfortunatly, this model (when trained with all the train data) resulted in an 27 MAE when submitted to the platform. This indicates overfitting and that there must be considerable differences between the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "optimizers=[Tree_optimizer, Forest_optimizer, AdaTree_optimizer, KNN_optimizer, SVR_optimizer]\n",
    "weeks = [1,2,3,4]\n",
    "\n",
    "n_total = len(optimizers) * len(weeks) \n",
    "\n",
    "\n",
    "results=[]\n",
    "best_attempt = None\n",
    "best_score = np.inf\n",
    "idx=0\n",
    "for opt in optimizers:\n",
    "    for w in weeks:\n",
    "        pipeline = create_pipeline(attr, n_weeks=w, estimator_optimizer=opt, pca=None)\n",
    "        pipeline.fit(X_train_1, y_train)\n",
    "        score = pipeline.named_steps['est_opt'].best_score_\n",
    "        best_estimator = pipeline.named_steps['est_opt'].best_estimator_\n",
    "        attempt = [best_estimator, w, score]\n",
    "        if abs(score) < best_score:\n",
    "            best_score = abs(score)\n",
    "            best_attempt = attempt\n",
    "            print('\\nBest score of {} with the estimator {}'.format(best_score, best_estimator))\n",
    "        idx+=1\n",
    "        print(str(idx) + '/' + str(n_total), end='\\t')\n",
    "        results.append(attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=2,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " 3,\n",
       " -17.87464878333245]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "pipeline = create_pipeline(attr, n_weeks=3, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1)\n",
    "\n",
    "model = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=2, n_estimators=13, n_jobs=-1, random_state=random_n)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pipeline.transform(X_test_1)\n",
    "pred = model.predict(X_test)\n",
    "pred = list(map(lambda x: int(np.round(x)), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(pred, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the last infected\n",
    "* As we could see on the analysis notebook, the number of infected on any week is highly linked to the number of infected at its previous weeks. Including the number of infected (or at least an approximation) on the previous weeks should be key to very accurate predictions.\n",
    "* For this sake, we created the `LastInfected` module which is included in the pipeline.\n",
    "* After the exaustive search, the best model was the SVR which obtained an MAE of 6.52 on the training dataset, which is a great improvement.\n",
    "* Given that we are making sequential predictions, i.e.: the prediction from one week relies on the prediction from the previous weeks, we must make the transformations and predictions one by one.\n",
    "* The submission MAE was approximately 26, which is an improvement and is not bad given that the `total_cases` feature on the training set ranges from 0 to 400. However, we were expecting a much smaller result.\n",
    "\n",
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "optimizers=[Tree_optimizer, Forest_optimizer, AdaTree_optimizer, KNN_optimizer, SVR_optimizer]\n",
    "weeks = [1, 2, 3]\n",
    "weeks_infected = [2, 3, 4]\n",
    "pca = [PCA(0.95), None]\n",
    "\n",
    "n_total = len(optimizers) * len(weeks) * len(weeks_infected) * len(pca)\n",
    "\n",
    "results=[]\n",
    "best_attempt = None\n",
    "best_score = np.inf\n",
    "idx=0\n",
    "for opt in optimizers:\n",
    "    for w in weeks:\n",
    "        for wi in weeks_infected:\n",
    "            for p in pca:\n",
    "                pipeline = create_pipeline(attr, n_weeks=w, n_weeks_infected=wi, estimator_optimizer=opt, pca=None)\n",
    "                pipeline.fit(X_train_1, y_train)\n",
    "                score = pipeline.named_steps['est_opt'].best_score_\n",
    "                best_estimator = pipeline.named_steps['est_opt'].best_estimator_\n",
    "                attempt = [best_estimator, w, wi, p, score]\n",
    "                if abs(score) < best_score:\n",
    "                    best_score = abs(score)\n",
    "                    best_attempt = attempt\n",
    "                    print('\\nBest score of {} with the estimator {}'.format(best_score, best_estimator))\n",
    "                idx+=1\n",
    "                print(str(idx) + '/' + str(n_total), end='\\t')\n",
    "                results.append(attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       " 1,\n",
       " 3,\n",
       " None,\n",
       " -6.522347109745663]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel= 'linear', C=5191, gamma='scale')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 24)\n"
     ]
    }
   ],
   "source": [
    "X_test_1 = pd.read_csv('data/dengue_features_test.csv')\n",
    "print(X_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One by one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.predict_in_order import predict_in_order\n",
    "predictions = predict_in_order(X_test_1, model, pipeline)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(predictions, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One by one prediction with noise\n",
    "* We believe the reason why our predictions were not so great, was because this kind of prediction is very prone to a snowball effect on errors.\n",
    "* To solve this we came up with an idea: Our problem was currently being trained on data which has all `last_infected` columns with the exact correct values. However, when we are predicting with the test set, the values we use on `last_infected` are mere predictions. By adding random noise to the `last_infected` columns on the training data we would make our model more \"prepared\" to accept entries in which the `last_infected` columns are not so accurate.\n",
    "* However for this solution we need to know both: the mean of the error and its standard deviation (*std*), so that we can reproduce the error by a gaussian distribution. We already know the mean (MAE), we just need to know the *std*\n",
    "* When dealing with the test data, the noise adding feature of the pipeline must be disabled, otherwise our predictions will be based on 2 layers of noise: our \"synthetic\" noise and the one created by the predictive model.\n",
    "* The submission's MAE increased again to approximately 27. \n",
    "* A very for why it isn't working is that the error when y is low is much smaller than when y is high.\n",
    "\n",
    "### Calculating an approximation of the *std*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = ShuffleSplit(n_splits=1, train_size=1000, test_size=None, random_state=random_n)\n",
    "for train, test in sp.split(X_train, y_train):\n",
    "    X_train_std = X_train[train]\n",
    "    y_train_std = y_train[train]\n",
    "    X_test_std = X_train[test]\n",
    "    y_test_std = y_train[test]\n",
    "X_train_std.shape, y_train_std.shape\n",
    "X_test_std.shape, y_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel= 'linear', C=5191, gamma='scale')\n",
    "model.fit(X_train_std, y_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.7785087719298245, 10.959317651673116)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_std)\n",
    "predictions = list(map(lambda x: int(np.round(x)), predictions))\n",
    "errors = list(map(abs, predictions - y_test_std))\n",
    "np.mean(errors), np.std(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the noise and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=True, noise_mean=6.78, noise_std=10.96, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disabling the noise and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "pipeline.fit_transform(X_train_1, y_train)\n",
    "\n",
    "predictions = predict_in_order(X_test_1, model, pipeline)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(predictions, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test split of tail\n",
    "* To simulate what we are doing with the test data, we are going to split the train data, for each city, by sampling N entries from the tail of each city for testing.\n",
    "* We now have 580 entries of train data and 871 entres of test data, to figure out what is wrong.\n",
    "* Since we can't use `RandomizedSearchCV` with this prediction mode (the one-by-one explained before), we opted to implement our own exhaustive search tool.\n",
    "* Here we only worked with the `RandomForestRegressor` because it brought results almost as good as the `SVR` model and took far less time training.\n",
    "* The optimal model turned out to be `RandomForestRegressor` with with 50 estimators and a maximum depth of 5.\n",
    "* Even though we obtain a MAE of approximately 17 on our custom test set (which has twice as many entries as the one from the competition), when we submit the data with that model we obtain a MAE of approximately 30.\n",
    "* We are hoping to be able to improve this result on the phase 2 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((933, 24), (933,), (518, 24), (518,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_sj = X_train_1['city'] == 'sj'\n",
    "X_sj = X_train_1[idx_sj]\n",
    "y_sj = y_train[idx_sj]\n",
    "\n",
    "idx_iq = X_train_1['city'] == 'iq'\n",
    "X_iq = X_train_1[idx_iq]\n",
    "y_iq = y_train[idx_iq]\n",
    "\n",
    "X_sj.shape, y_sj.shape, X_iq.shape, y_iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((373, 24), (560, 24), (373,), (560,), (207, 24), (311, 24), (207,), (311,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "l = train_test_split(X_sj, y_sj, train_size=0.4, test_size=None, shuffle=False)\n",
    "X_train_sj = l[0]\n",
    "X_test_sj = l[1]\n",
    "y_train_sj = l[2]\n",
    "y_test_sj = l[3]\n",
    "\n",
    "l = train_test_split(X_iq, y_iq, train_size=0.4, test_size=None, shuffle=False)\n",
    "X_train_iq = l[0]\n",
    "X_test_iq = l[1]\n",
    "y_train_iq = l[2]\n",
    "y_test_iq = l[3]\n",
    "\n",
    "X_train_sj.shape, X_test_sj.shape, y_train_sj.shape, y_test_sj.shape, X_train_iq.shape, X_test_iq.shape, y_train_iq.shape, y_test_iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((580, 24), (580,), (871, 24), (871,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = pd.concat([X_train_sj, X_train_iq])\n",
    "y_train_2 = pd.concat([y_train_sj, y_train_iq])\n",
    "X_test_2 = pd.concat([X_test_sj, X_test_iq])\n",
    "y_test_2 = pd.concat([y_test_sj, y_test_iq])\n",
    "\n",
    "X_train_2.reset_index(drop=True, inplace=True)\n",
    "X_test_2.reset_index(drop=True, inplace=True)\n",
    "y_train_2.reset_index(drop=True, inplace=True)\n",
    "y_test_2.reset_index(drop=True, inplace=True)\n",
    "X_train_2.shape, y_train_2.shape, X_test_2.shape, y_test_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.044776119402986, (50, 5))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "estimators = [25, 50, 75]\n",
    "depth = [2,3,4,5]\n",
    "\n",
    "best_mae=np.inf\n",
    "best=None\n",
    "for est in estimators:\n",
    "    for d in depth:\n",
    "        model = RandomForestRegressor(criterion='mae', n_estimators=est, max_depth=d)\n",
    "        model.fit(X_train, y_train_2)\n",
    "\n",
    "\n",
    "        #pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "        #pipeline.fit_transform(X_train_2, y_train_2)\n",
    "\n",
    "        pred = predict_in_order(X_test_2, model=model, pipeline=pipeline)\n",
    "\n",
    "        mae = mean_absolute_error(pred, y_test_2)\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best = (est, d)\n",
    "\n",
    "best_mae, best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_2, y_train_2)\n",
    "\n",
    "model = RandomForestRegressor(criterion='mae', n_estimators=50, max_depth=5)\n",
    "model.fit(X_train, y_train_2)\n",
    "\n",
    "pred = predict_in_order(X_test_1, model=model, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(pred, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
