{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'year',\n",
       " 'weekofyear',\n",
       " 'week_start_date',\n",
       " 'ndvi_ne',\n",
       " 'ndvi_nw',\n",
       " 'ndvi_se',\n",
       " 'ndvi_sw',\n",
       " 'precipitation_amt_mm',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_tdtr_k',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'station_precip_mm']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = pd.read_csv('data/dengue_features_train.csv')\n",
    "y_train = pd.read_csv('data/dengue_labels_train.csv')['total_cases']\n",
    "attr = list(X_train_1)\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bools_to_indexes(booleans):\n",
    "    r = []\n",
    "    for idx, x in enumerate(booleans):\n",
    "        if x:\n",
    "            r.append(idx)\n",
    "    return r\n",
    "\n",
    "idx = bools_to_indexes(X_train_1['weekofyear'] == 53)\n",
    "y_train.drop(idx, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train_1.drop(idx, inplace=True)\n",
    "X_train_1.reset_index(drop=True, inplace=True)\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "score_metric='neg_mean_absolute_error'\n",
    "jobs=-1 #-1 to make it execute in parallel\n",
    "verbose_level = 0\n",
    "random_n = 42\n",
    "base_args = {'estimator': None, 'param_distributions': None, 'n_iter': None, 'scoring': score_metric, 'n_jobs': jobs, 'cv': None, 'verbose': verbose_level, 'random_state': random_n, 'return_train_score': True, 'iid': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "* The results with the kernel *sigmoid* and *poly* were too bad, so we removed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 20\n",
    "C = sp_randint(0, 10000)\n",
    "params = {'kernel':['linear'], 'gamma':['scale'], 'C': C}\n",
    "SVR_optimizer = RandomizedSearchCV(estimator=SVR(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "* 18.01 - with 2 previous weeks & without PCA & with (max_depth=6, min_samples_leaf=0.1611807565247405, min_samples_split=0.11193019906931466)\n",
    "* 18.29 - With PCA at 0.9\n",
    "* 18.27 - With PCA at 0.95\n",
    "* 18.36 - With PCA at 0.65. PCA appears to be only making the model worse.\n",
    "* 18.38 - Without PCA and with previous weeks. Clearly the previous weeks are useful\n",
    "* 17.87 - Without PCA and with 3 previous weeks\n",
    "* 17.86 - Without PCA and with 4 previous weeks\n",
    "* 18.28 - With PCA 0.95 and 3 previous weeks fixed\n",
    "* 9.16 - Without PCA, with 3 weeks and 1 last infection (max_depth=5, min_samples_leaf=0.03, min_samples_split=0.108)\n",
    "* **9.04** - Without PCA, with 3 weeks and 1 last infection (max_depth=5, min_samples_leaf=0.03, min_samples_split=0.108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 100\n",
    "min_samples = sp_uniform(0.01, 0.35)\n",
    "params = {'criterion':['mae'], 'max_depth': sp_randint(2, 10), 'min_samples_split': min_samples, 'min_samples_leaf': min_samples}\n",
    "Tree_optimizer = RandomizedSearchCV(estimator=DecisionTreeRegressor(), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "* 18.34 With 4 previous weeks and without PCA\n",
    "* 17.79 With fixed 3 previous weeks and PCA at 0.95 (n_estimators= ?, max_depth = 2, min_samples_leaf=0.112, min_samples_split=0.224)\n",
    "* 17.74 With fixed 3 previous weeks and without PCA (n_estimators= 13 max_depth = 5, min_samples_leaf=0.09, min_samples_split=0.24)\n",
    "* **9.13** with 3 previous weeks and 1 last infected (n_estimators=9 max_depth = 9, min_samples_leaf=0.014, min_samples_split=0.07)\n",
    "* 9.22 with 3 previous weeks and 3 last infected (n_estimators=9 max_depth = 9, min_samples_leaf=0.014, min_samples_split=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 40\n",
    "params = {'n_estimators': sp_randint(2,50), 'criterion':['mae'], 'max_depth': sp_randint(2, 10)}\n",
    "Forest_optimizer = RandomizedSearchCV(estimator=RandomForestRegressor(n_jobs=-1), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost of Trees\n",
    "* 10.78 - With 3 last weeks a 3 last infected \n",
    "* **8.49** - With 3 last weeks a 3 last infected and only max_depth tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 20\n",
    "params = {'n_estimators': sp_randint(40, 100), 'base_estimator__criterion':['mae'], 'base_estimator__max_depth': sp_randint(2,7)}\n",
    "AdaTree_optimizer = RandomizedSearchCV(estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor()), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "* 21.349 - with PCA at 0.65 & 2 previous weeks\n",
    "* 20.36  - without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=10\n",
    "n_iter_search = 100\n",
    "params = {'n_neighbors': sp_randint(3,150), 'weights': ['uniform', 'distance']}\n",
    "KNN_optimizer = RandomizedSearchCV(estimator=KNeighborsRegressor(n_jobs=-1), param_distributions=params, n_iter=n_iter_search, scoring=score_metric, n_jobs=jobs, cv=k_folds, verbose=verbose_level, random_state=random_n, return_train_score=True, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "* Interestingly, PCA makes all the models worst in this case.\n",
    "* After the exaustive search, the best model was the SVR which obtained an MAE of 6.52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score of 10.757898351648352 with the estimator DecisionTreeRegressor(criterion='mae', max_depth=7, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=0.048518173584686866,\n",
      "           min_samples_split=0.08977730688967958,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')\n",
      "1/4\t\n",
      "Best score of 8.57545699492815 with the estimator RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=26, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "2/4\t3/4\t4/4\t"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "optimizers=[Tree_optimizer, Forest_optimizer, AdaTree_optimizer, KNN_optimizer]#, SVR_optimizer]\n",
    "weeks = [1]\n",
    "weeks_infected = [3]\n",
    "pca = [None]\n",
    "\n",
    "n_total = len(optimizers) * len(weeks) * len(weeks_infected) * len(pca)\n",
    "\n",
    "results=[]\n",
    "best_attempt = None\n",
    "best_score = np.inf\n",
    "idx=0\n",
    "for opt in optimizers:\n",
    "    for w in weeks:\n",
    "        for wi in weeks_infected:\n",
    "            for p in pca:\n",
    "                pipeline = create_pipeline(attr, n_weeks=w, n_weeks_infected=wi, estimator_optimizer=opt, add_noise=True, noise_mean=6.5, noise_std=6.5, pca=None)\n",
    "                pipeline.fit(X_train_1, y_train)\n",
    "                score = pipeline.named_steps['est_opt'].best_score_\n",
    "                best_estimator = pipeline.named_steps['est_opt'].best_estimator_\n",
    "                attempt = [best_estimator, w, wi, p, score]\n",
    "                if abs(score) < best_score:\n",
    "                    best_score = abs(score)\n",
    "                    best_attempt = attempt\n",
    "                    print('\\nBest score of {} with the estimator {}'.format(best_score, best_estimator))\n",
    "                idx+=1\n",
    "                print(str(idx) + '/' + str(n_total), end='\\t')\n",
    "                results.append(attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=['estimator', 'weeks', 'weeks_infected', 'PCA', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       " 1,\n",
       " 3,\n",
       " None,\n",
       " -6.522347109745663]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel= 'linear', C=5191, gamma='scale')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 24)\n"
     ]
    }
   ],
   "source": [
    "X_test_1 = pd.read_csv('data/dengue_features_test.csv')\n",
    "print(X_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One by one prediction\n",
    "* Given that we are making sequential predictions, i.e.: the prediction from a week relies on the prediction from the previous weeks, we must make the transformations and predictions one by one.\n",
    "* Given that this kind of prediction is very prone to a snowball effect on errors our first solution had an error of 26. To solve this we came up with the idea of adding noise to the train data. However for this solution we need to know both: the mean of the error and its standard deviation (*std*). We already know the mean (MAE), we just need to know the *std*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=[]\n",
    "for idx in range(X_test_1.shape[0]):\n",
    "    x = pipeline.transform(X_test_1.loc[idx:idx,:])\n",
    "    pred = model.predict(x)\n",
    "    pred = int(np.round(pred))\n",
    "    pipeline.named_steps['l_infected'].append_y(pred)\n",
    "    predictions.append(pred)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating an approximation of the *std*\n",
    "* It is approximately 10.9. We can see that the MAE is close to the one calculated in the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = ShuffleSplit(n_splits=1, train_size=1000, test_size=None, random_state=random_n)\n",
    "for train, test in sp.split(X_train, y_train):\n",
    "    X_train_std = X_train[train]\n",
    "    y_train_std = y_train[train]\n",
    "    X_test_std = X_train[test]\n",
    "    y_test_std = y_train[test]\n",
    "X_train_std.shape, y_train_std.shape\n",
    "X_test_std.shape, y_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5191, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel= 'linear', C=5191, gamma='scale')\n",
    "model.fit(X_train_std, y_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.7785087719298245, 10.959317651673116)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_std)\n",
    "predictions = list(map(lambda x: int(np.round(x)), predictions))\n",
    "errors = list(map(abs, predictions - y_test_std))\n",
    "np.mean(errors), np.std(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.53353, 4.950353092366241)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice, gauss\n",
    "r=[]\n",
    "for _ in range(100000):\n",
    "    r.append(int(np.round(choice([-1,1]) * gauss(mu=0, sigma=8.2))))\n",
    "r=np.abs(r)\n",
    "np.mean(r), np.std(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One by one prediction with noise\n",
    "* When dealing with the test data, the noise adding feature of the pipeline must be disabled, otherwise our predictions will be based on 2 layers of noise: our synthetic noise and the one created by the predictive model.\n",
    "* A very likely guess is that the errors when y is low is much smaller than when y is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=True, noise_mean=0, noise_std=8.2, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(criterion='mae', n_estimators=100, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=3,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "pipeline.fit_transform(X_train_1, y_train)\n",
    "\n",
    "predict_in_order(X_test_1, model, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(predictions, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>last_weeks_0_reanalysis_tdtr_k</th>\n",
       "      <th>last_weeks_0_station_avg_temp_c</th>\n",
       "      <th>last_weeks_0_station_diur_temp_rng_c</th>\n",
       "      <th>last_weeks_0_station_max_temp_c</th>\n",
       "      <th>last_weeks_0_station_min_temp_c</th>\n",
       "      <th>last_weeks_0_station_precip_mm</th>\n",
       "      <th>last_infected_0</th>\n",
       "      <th>last_infected_1</th>\n",
       "      <th>last_infected_2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018900</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>78.60</td>\n",
       "      <td>298.492857</td>\n",
       "      <td>298.550000</td>\n",
       "      <td>294.527143</td>\n",
       "      <td>301.1</td>\n",
       "      <td>296.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957143</td>\n",
       "      <td>27.042857</td>\n",
       "      <td>7.514286</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018000</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>0.082043</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>12.56</td>\n",
       "      <td>298.475714</td>\n",
       "      <td>298.557143</td>\n",
       "      <td>294.395714</td>\n",
       "      <td>300.8</td>\n",
       "      <td>296.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.128571</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.057143</td>\n",
       "      <td>33.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>75.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>3.66</td>\n",
       "      <td>299.455714</td>\n",
       "      <td>299.357143</td>\n",
       "      <td>295.308571</td>\n",
       "      <td>302.2</td>\n",
       "      <td>296.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>26.071429</td>\n",
       "      <td>5.557143</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.019867</td>\n",
       "      <td>0.124329</td>\n",
       "      <td>0.125686</td>\n",
       "      <td>0.00</td>\n",
       "      <td>299.690000</td>\n",
       "      <td>299.728571</td>\n",
       "      <td>294.402857</td>\n",
       "      <td>303.0</td>\n",
       "      <td>296.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.062267</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.76</td>\n",
       "      <td>299.780000</td>\n",
       "      <td>299.671429</td>\n",
       "      <td>294.760000</td>\n",
       "      <td>302.3</td>\n",
       "      <td>297.3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.342857</td>\n",
       "      <td>28.057143</td>\n",
       "      <td>6.271429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.044000</td>\n",
       "      <td>-0.030467</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.083529</td>\n",
       "      <td>71.17</td>\n",
       "      <td>299.768571</td>\n",
       "      <td>299.728571</td>\n",
       "      <td>295.314286</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.542857</td>\n",
       "      <td>27.614286</td>\n",
       "      <td>7.085714</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>84.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.044300</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.132271</td>\n",
       "      <td>0.159157</td>\n",
       "      <td>48.99</td>\n",
       "      <td>300.062857</td>\n",
       "      <td>300.007143</td>\n",
       "      <td>295.650000</td>\n",
       "      <td>302.4</td>\n",
       "      <td>297.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.171429</td>\n",
       "      <td>32.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.044300</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.144371</td>\n",
       "      <td>0.116729</td>\n",
       "      <td>30.81</td>\n",
       "      <td>300.484286</td>\n",
       "      <td>300.578571</td>\n",
       "      <td>295.997143</td>\n",
       "      <td>303.5</td>\n",
       "      <td>297.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>6.042857</td>\n",
       "      <td>31.1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>91.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.100571</td>\n",
       "      <td>0.117329</td>\n",
       "      <td>8.02</td>\n",
       "      <td>300.601429</td>\n",
       "      <td>300.621429</td>\n",
       "      <td>296.268571</td>\n",
       "      <td>302.5</td>\n",
       "      <td>298.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>28.757143</td>\n",
       "      <td>6.985714</td>\n",
       "      <td>34.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.106660</td>\n",
       "      <td>0.155429</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>17.52</td>\n",
       "      <td>300.497143</td>\n",
       "      <td>300.528571</td>\n",
       "      <td>296.411429</td>\n",
       "      <td>302.3</td>\n",
       "      <td>298.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>28.657143</td>\n",
       "      <td>6.242857</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.9</td>\n",
       "      <td>28.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  precipitation_amt_mm  \\\n",
       "0 -0.018900 -0.018900  0.102729  0.091200                 78.60   \n",
       "1 -0.018000 -0.012400  0.082043  0.072314                 12.56   \n",
       "2 -0.001500 -0.012400  0.151083  0.091529                  3.66   \n",
       "3 -0.001500 -0.019867  0.124329  0.125686                  0.00   \n",
       "4  0.056800  0.039833  0.062267  0.075914                  0.76   \n",
       "5 -0.044000 -0.030467  0.132000  0.083529                 71.17   \n",
       "6 -0.044300 -0.024925  0.132271  0.159157                 48.99   \n",
       "7 -0.044300  0.082150  0.144371  0.116729                 30.81   \n",
       "8  0.010800  0.049900  0.100571  0.117329                  8.02   \n",
       "9  0.072667  0.106660  0.155429  0.164900                 17.52   \n",
       "\n",
       "   reanalysis_air_temp_k  reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  \\\n",
       "0             298.492857             298.550000                   294.527143   \n",
       "1             298.475714             298.557143                   294.395714   \n",
       "2             299.455714             299.357143                   295.308571   \n",
       "3             299.690000             299.728571                   294.402857   \n",
       "4             299.780000             299.671429                   294.760000   \n",
       "5             299.768571             299.728571                   295.314286   \n",
       "6             300.062857             300.007143                   295.650000   \n",
       "7             300.484286             300.578571                   295.997143   \n",
       "8             300.601429             300.621429                   296.268571   \n",
       "9             300.497143             300.528571                   296.411429   \n",
       "\n",
       "   reanalysis_max_air_temp_k  reanalysis_min_air_temp_k  ...  \\\n",
       "0                      301.1                      296.4  ...   \n",
       "1                      300.8                      296.7  ...   \n",
       "2                      302.2                      296.4  ...   \n",
       "3                      303.0                      296.9  ...   \n",
       "4                      302.3                      297.3  ...   \n",
       "5                      301.9                      297.6  ...   \n",
       "6                      302.4                      297.5  ...   \n",
       "7                      303.5                      297.5  ...   \n",
       "8                      302.5                      298.5  ...   \n",
       "9                      302.3                      298.7  ...   \n",
       "\n",
       "   last_weeks_0_reanalysis_tdtr_k  last_weeks_0_station_avg_temp_c  \\\n",
       "0                        3.957143                        27.042857   \n",
       "1                        3.128571                        26.528571   \n",
       "2                        2.571429                        26.071429   \n",
       "3                        4.428571                        27.928571   \n",
       "4                        4.342857                        28.057143   \n",
       "5                        3.542857                        27.614286   \n",
       "6                        2.857143                        28.000000   \n",
       "7                        3.157143                        27.400000   \n",
       "8                        3.900000                        28.757143   \n",
       "9                        2.785714                        28.657143   \n",
       "\n",
       "   last_weeks_0_station_diur_temp_rng_c  last_weeks_0_station_max_temp_c  \\\n",
       "0                              7.514286                             31.7   \n",
       "1                              7.057143                             33.3   \n",
       "2                              5.557143                             30.0   \n",
       "3                              7.785714                             32.8   \n",
       "4                              6.271429                             33.3   \n",
       "5                              7.085714                             33.3   \n",
       "6                              5.171429                             32.8   \n",
       "7                              6.042857                             31.1   \n",
       "8                              6.985714                             34.4   \n",
       "9                              6.242857                             32.8   \n",
       "\n",
       "   last_weeks_0_station_min_temp_c  last_weeks_0_station_precip_mm  \\\n",
       "0                             23.3                             0.3   \n",
       "1                             21.7                            75.2   \n",
       "2                             22.2                            34.3   \n",
       "3                             22.8                             3.0   \n",
       "4                             24.4                             0.3   \n",
       "5                             23.3                            84.1   \n",
       "6                             25.0                            27.7   \n",
       "7                             23.3                            91.7   \n",
       "8                             24.4                             0.3   \n",
       "9                             23.9                            28.7   \n",
       "\n",
       "   last_infected_0  last_infected_1  last_infected_2  pred  \n",
       "0              5.0              3.0              1.0     6  \n",
       "1              6.0              5.0              3.0     6  \n",
       "2              6.0              6.0              5.0     6  \n",
       "3              6.0              6.0              6.0     6  \n",
       "4              6.0              6.0              6.0     6  \n",
       "5              6.0              6.0              6.0     6  \n",
       "6              6.0              6.0              6.0     6  \n",
       "7              6.0              6.0              6.0     6  \n",
       "8              6.0              6.0              6.0     6  \n",
       "9              6.0              6.0              6.0     6  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_test_f, pd.DataFrame(predictions, columns=['pred'])], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.860576923076923"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(model.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371.265"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test split of tail\n",
    "* To simulate what we are doing with the test data, we are going to split the train data, for each city, by sampling N entries from the tail of each city for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((933, 24), (933,), (518, 24), (518,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_sj = X_train_1['city'] == 'sj'\n",
    "X_sj = X_train_1[idx_sj]\n",
    "y_sj = y_train[idx_sj]\n",
    "\n",
    "idx_iq = X_train_1['city'] == 'iq'\n",
    "X_iq = X_train_1[idx_iq]\n",
    "y_iq = y_train[idx_iq]\n",
    "\n",
    "X_sj.shape, y_sj.shape, X_iq.shape, y_iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((466, 24), (467, 24), (466,), (467,), (259, 24), (259, 24), (259,), (259,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "l = train_test_split(X_sj, y_sj, train_size=0.5, test_size=None, shuffle=False)\n",
    "X_train_sj = l[0]\n",
    "X_test_sj = l[1]\n",
    "y_train_sj = l[2]\n",
    "y_test_sj = l[3]\n",
    "\n",
    "l = train_test_split(X_iq, y_iq, train_size=0.5, test_size=None, shuffle=False)\n",
    "X_train_iq = l[0]\n",
    "X_test_iq = l[1]\n",
    "y_train_iq = l[2]\n",
    "y_test_iq = l[3]\n",
    "\n",
    "X_train_sj.shape, X_test_sj.shape, y_train_sj.shape, y_test_sj.shape, X_train_iq.shape, X_test_iq.shape, y_train_iq.shape, y_test_iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 24), (725,), (726, 24), (726,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = pd.concat([X_train_sj, X_train_iq])\n",
    "y_train_2 = pd.concat([y_train_sj, y_train_iq])\n",
    "X_test_2 = pd.concat([X_test_sj, X_test_iq])\n",
    "y_test_2 = pd.concat([y_test_sj, y_test_iq])\n",
    "\n",
    "X_train_2.reset_index(drop=True, inplace=True)\n",
    "X_test_2.reset_index(drop=True, inplace=True)\n",
    "y_train_2.reset_index(drop=True, inplace=True)\n",
    "y_test_2.reset_index(drop=True, inplace=True)\n",
    "X_train_2.shape, y_train_2.shape, X_test_2.shape, y_test_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=3,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(criterion='mae', n_estimators=150, max_depth=3)\n",
    "model.fit(X_train, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "pipeline.fit_transform(X_train_2, y_train_2)\n",
    "\n",
    "pred = predict_in_order(X_test_2, model=model, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.414600550964188"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(pred, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "from utils.predict_in_order import predict_in_order\n",
    "\n",
    "pipeline = create_pipeline(attr, n_weeks=1, n_weeks_infected=3, add_noise=False, pca=None)\n",
    "X_train = pipeline.fit_transform(X_train_1, y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = predict_in_order(X_test_1, model=model, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(pred, columns=['total_cases'])\n",
    "x_3 = X_test_1.iloc[:,:3].copy()\n",
    "submit = pd.concat([x_3, submit], axis=1)\n",
    "submit.to_csv('data/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
