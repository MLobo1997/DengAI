{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'year',\n",
       " 'weekofyear',\n",
       " 'week_start_date',\n",
       " 'ndvi_ne',\n",
       " 'ndvi_nw',\n",
       " 'ndvi_se',\n",
       " 'ndvi_sw',\n",
       " 'precipitation_amt_mm',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_tdtr_k',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'station_precip_mm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = pd.read_csv('data/dengue_features_train.csv')\n",
    "y_train = pd.read_csv('data/dengue_labels_train.csv')['total_cases']\n",
    "attr = list(X_train_1)\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bools_to_indexes(booleans):\n",
    "    r = []\n",
    "    for idx, x in enumerate(booleans):\n",
    "        if x:\n",
    "            r.append(idx)\n",
    "    return r\n",
    "\n",
    "idx = bools_to_indexes(X_train_1['weekofyear'] == 53)\n",
    "y_train.drop(idx, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train_1.drop(idx, inplace=True)\n",
    "X_train_1.reset_index(drop=True, inplace=True)\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.OurPipeline import create_pipeline\n",
    "\n",
    "pipeline = create_pipeline(attr)\n",
    "X_train = pipeline.fit_transform(X_train_1)\n",
    "N, M = X_train.shape\n",
    "N, M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric='neg_mean_absolute_error'\n",
    "n_jobs=-1\n",
    "iid = False\n",
    "verbose_level = 2\n",
    "k_folds=10 \n",
    "n_iter_search=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP with Scikit-Learn\n",
    "* First we will try with a simple Multilayer Perceptron.\n",
    "* According to the book 'Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems', applying the RELU activation function to all the hidden layers is a good idea.\n",
    "* Here we will simply be searching through the different initial learning rates\n",
    "* The ideal number of layers appears to be 7, however the scores are still very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining generic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "train_algorithm = 'adam'\n",
    "learn_rate_mode = 'adaptive'\n",
    "learn_rate_val = 0.001\n",
    "batch_size = 200\n",
    "max_iter = 5000\n",
    "random_n = 42\n",
    "tol_val = 1e-4\n",
    "n_iter_tol = 20\n",
    "verb=False\n",
    "\n",
    "early_stop=True\n",
    "val_faction = 0.1\n",
    "\n",
    "params = {\n",
    "    #'hidden_layer_sizes': [sp_randint(30, 52), sp_randint(16, 30), sp_randint(4, 16)],\n",
    "    'learning_rate_init': sp_uniform(1e-4, 1)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPRegressor(activation='relu', alpha=0.0001, batch_size=200, beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "        hidden_layer_sizes=[35, 25, 20, 15, 10], learning_rate='adaptive',\n",
       "        learning_rate_init=0.04694728278293715, max_iter=5000, momentum=0.9,\n",
       "        n_iter_no_change=20, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " -20.78080881244646)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_per_layer = [35, 25, 20, 15, 10]\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=neurons_per_layer, activation=activation, max_iter=max_iter, solver=train_algorithm, learning_rate=learn_rate_mode, batch_size=batch_size, random_state=random_n, tol=tol_val, verbose=verb, early_stopping=early_stop, validation_fraction=val_faction, n_iter_no_change=n_iter_tol)\n",
    "MLP_Optimizer = RandomizedSearchCV(mlp, param_distributions=params, cv=k_folds, n_iter=n_iter_search, scoring=score_metric, n_jobs=n_jobs, verbose=verbose_level, iid=iid, return_train_score=True)\n",
    "MLP_Optimizer.fit(X_train, y_train)\n",
    "MLP_Optimizer.best_estimator_, MLP_Optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPRegressor(activation='relu', alpha=0.0001, batch_size=200, beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "        hidden_layer_sizes=[35, 25, 15, 10], learning_rate='adaptive',\n",
       "        learning_rate_init=0.0866318376475216, max_iter=5000, momentum=0.9,\n",
       "        n_iter_no_change=20, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " -19.513873846292523)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_per_layer = [35, 25, 15, 10]\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=neurons_per_layer, activation=activation, max_iter=max_iter, solver=train_algorithm, learning_rate=learn_rate_mode, batch_size=batch_size, random_state=random_n, tol=tol_val, verbose=verb, early_stopping=early_stop, validation_fraction=val_faction, n_iter_no_change=n_iter_tol)\n",
    "MLP_Optimizer = RandomizedSearchCV(mlp, param_distributions=params, cv=k_folds, n_iter=n_iter_search, scoring=score_metric, n_jobs=n_jobs, verbose=verbose_level, iid=iid, return_train_score=True)\n",
    "MLP_Optimizer.fit(X_train, y_train)\n",
    "MLP_Optimizer.best_estimator_, MLP_Optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   40.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPRegressor(activation='relu', alpha=0.0001, batch_size=200, beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "        hidden_layer_sizes=[35, 20, 10], learning_rate='adaptive',\n",
       "        learning_rate_init=0.134954482930001, max_iter=5000, momentum=0.9,\n",
       "        n_iter_no_change=20, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " -21.349379403662667)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_per_layer = [35, 20, 10]\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=neurons_per_layer, activation=activation, max_iter=max_iter, solver=train_algorithm, learning_rate=learn_rate_mode, batch_size=batch_size, random_state=random_n, tol=tol_val, verbose=verb, early_stopping=early_stop, validation_fraction=val_faction, n_iter_no_change=n_iter_tol)\n",
    "MLP_Optimizer = RandomizedSearchCV(mlp, param_distributions=params, cv=k_folds, n_iter=n_iter_search, scoring=score_metric, n_jobs=n_jobs, verbose=verbose_level, iid=iid, return_train_score=True)\n",
    "MLP_Optimizer.fit(X_train, y_train)\n",
    "MLP_Optimizer.best_estimator_, MLP_Optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPRegressor(activation='relu', alpha=0.0001, batch_size=200, beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "        hidden_layer_sizes=[30, 15], learning_rate='adaptive',\n",
       "        learning_rate_init=0.09571433102280714, max_iter=5000, momentum=0.9,\n",
       "        n_iter_no_change=20, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " -21.32883347845756)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_per_layer = [30, 15]\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=neurons_per_layer, activation=activation, max_iter=max_iter, solver=train_algorithm, learning_rate=learn_rate_mode, batch_size=batch_size, random_state=random_n, tol=tol_val, verbose=verb, early_stopping=early_stop, validation_fraction=val_faction, n_iter_no_change=n_iter_tol)\n",
    "MLP_Optimizer = RandomizedSearchCV(mlp, param_distributions=params, cv=k_folds, n_iter=n_iter_search, scoring=score_metric, n_jobs=n_jobs, verbose=verbose_level, iid=iid, return_train_score=True)\n",
    "MLP_Optimizer.fit(X_train, y_train)\n",
    "MLP_Optimizer.best_estimator_, MLP_Optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP with Keras on top of Tensorflow\n",
    "* We will just try the amount of layers (6) which gave the ideal results with the Sci-kit API. \n",
    "* The first layer cannot use the activation function RELU given that the data was standardized.\n",
    "* Sigmoid is okay given that its codomain is between 0 and 1 and that the RELU is linear above 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.0001\n",
    "optim = optimizers.Adam(lr=learn_rate)\n",
    "loss_fun = 'mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 35)                735       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                900       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,616\n",
      "Trainable params: 2,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils.MLP import create_mlp\n",
    "neurons_per_layer = [35, 25, 15, 10]\n",
    "\n",
    "network = create_mlp(neurons_per_layer=neurons_per_layer, nr_of_features=M, optim_func=optim, loss_func=loss_fun)\n",
    "network.summary()\n",
    "\n",
    "from utils.print_history_loss import print_history_loss\n",
    "\n",
    "history_fit = network.fit(X_train, y_train, epochs=500, batch_size=150, verbose=0, validation_split=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_history_loss(history_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified sampling\n",
    "* The learning curves obtained above are very odd. The validation starts with a very small loss that starts increasing as the model overfits the training data. This is probably because the validation data is very \"easy\" to predict or all the same. We are going to apply stratified sampling  in order to try and fix this. Y is a continuous variable, therefore stratification is tricky.\n",
    "* Stratified sampling result was absolutely what we needed as we can see in the learning curves below. It made the train and test data more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 20), (725,), (726, 20), (726,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#train_strat, test_strat = sss.split(X_train, y_train)\n",
    "\n",
    "# Create the bins. Given that y is not uniformly distributed at all (as you can see in the analysis notebook histogram), we created bins every 100 values.\n",
    "y_sorted = np.sort(y_train)\n",
    "bins = []\n",
    "for idx, val in enumerate(y_sorted):\n",
    "    if (idx % 100) == 0:\n",
    "        bins.append(val)\n",
    "\n",
    "# Save your Y values in a new ndarray,\n",
    "# broken down by the bins created above.\n",
    "\n",
    "y_binned = np.digitize(y_train, bins)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "for train_index, test_index in sss.split(X_train, y_binned):\n",
    "    X_train_strat, X_test_strat = X_train[train_index], X_train[test_index]\n",
    "    y_train_strat, y_test_strat = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "X_train_strat.shape, y_train_strat.shape, X_test_strat.shape, y_test_strat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model with EarlyStopping callback\n",
    "* Making the model stop training when there doesn't appear to be any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils.MLP import create_mlp\n",
    "from utils.print_history_loss import print_history_loss\n",
    "\n",
    "neurons_per_layer = [35, 25, 15, 10]\n",
    "\n",
    "network = create_mlp(neurons_per_layer=neurons_per_layer, nr_of_features=M, optim_func=optim, loss_func=loss_fun)\n",
    "network.summary()\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=5e-2, patience=500, verbose=2, mode='min', restore_best_weights=True)\n",
    "\n",
    "history_fit = network.fit(X_train_strat, y_train_strat, validation_data=(X_test_strat, y_test_strat), callbacks=[early_stop], epochs=10000, batch_size=150, verbose=0, shuffle=True)\n",
    "print_history_loss(history_fit)\n",
    "min(history_fit.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
